{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Tour\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "pipeline()ã¯ï¼Œäº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãŸã‚ã®æœ€ã‚‚ç°¡å˜ã§é«˜é€Ÿãªæ–¹æ³•ã§ã™ï¼\n",
    "pipline()ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ï¼Œæ§˜ã€…ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼Œç”»åƒï¼ŒéŸ³å£°ï¼‰ã®å¤šãã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã™ãã«åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n",
    "\n",
    "[Hugging Face models](https://huggingface.co/models)ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã§ï¼Œã‚¿ã‚¹ã‚¯ã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n",
    "\n",
    "ã¾ãšï¼Œpipeline()ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ï¼Œä½¿ç”¨ã—ãŸã„ã‚¿ã‚¹ã‚¯ã‚’æŒ‡å®šã—ã¾ã™ï¼\n",
    "ä»¥ä¸‹ã®ä¾‹ã§ã¯ï¼Œã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã¨å‘¼ã°ã‚Œã‚‹ï¼Œæ–‡ç« ãŒè‚¯å®šçš„ï¼ˆpositiveï¼‰ã‹å¦å®šçš„ï¼ˆnegativeï¼‰ã‹ã‚’åˆ¤å®šã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’æ‰±ã„ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/home/fujie/.conda/envs/py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline()ã¯ï¼Œã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã®ãŸã‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ï¼Œãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’è‡ªå‹•çš„ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ï¼\n",
    "2å›ç›®ä»¥é™ã®å‘¼ã³å‡ºã—ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ï¼Œãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒä¸è¦ã«ãªã‚Šã¾ã™ï¼\n",
    "\n",
    "ã§ã¯ï¼Œæ—©é€Ÿ classifier ã‚’ä½¿ã£ã¦ã¿ã¾ã—ã‚‡ã†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"we are very happy to show you the ğŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "çµæœã® `label` ã¯æ„Ÿæƒ…ã®ãƒ©ãƒ™ãƒ«ã‚’è¡¨ã—ï¼Œ`score` ã¯ãã®æ„Ÿæƒ…ã«å¯¾ã™ã‚‹ç¢ºä¿¡åº¦ã‚’è¡¨ã—ã¾ã™ï¼\n",
    "\n",
    "çµæœã¯ãƒªã‚¹ãƒˆã¨ã—ã¦ä¸ãˆã‚‰ã‚Œã¾ã™ï¼\n",
    "è¤‡æ•°ã®å…¥åŠ›ãŒä¸ãˆã‚‰ã‚ŒãŸå ´åˆã¯ï¼Œè¤‡æ•°ã®çµæœãŒãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã•ã‚Œã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998801946640015},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991856217384338}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I am happy\", \"I am sad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«è‡ªå‹•éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼\n",
    "\n",
    "ã¾ãš `pipeline()` ã‚’ä½¿ã£ã¦ speech_recognizer ã‚’ä½œæˆã—ã¾ã™ï¼\n",
    "ã‚¿ã‚¹ã‚¯ã¯ `automatic-speech-ecognition` ã¨ã—ï¼Œãƒ¢ãƒ‡ãƒ«ã« `facebook/wav2vec2-base-960h` ã‚’æŒ‡å®šã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "speech_recognizer = pipeline(\"automatic-speech-recognition\",\n",
    "                             model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼\n",
    "\n",
    "Hugging Face datasets ã«ã¤ã„ã¦ã¯åˆ¥é€”ï¼Œãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ãªã©ã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼\n",
    "\n",
    "ã“ã“ã§ã¯ï¼ŒMinDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset`ã®ä¸­ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°ã¯ 8kHz ã«ãªã£ã¦ã„ã¾ã™ï¼\n",
    "`speech_recognizer` ã¯ 16kHz ã‚’æƒ³å®šã—ã¦ã„ã‚‹ãŸã‚ï¼Œã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°ã®å¤‰æ›ã‚’ã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "speech_recognizer ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ï¼Œçµæœã‚’è¡¨ç¤ºã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT'},\n",
       " {'text': \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\"},\n",
       " {'text': \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\"},\n",
       " {'text': 'HOW DO I FURN A JOINA COUT'},\n",
       " {'text': 'CAN NOW YOU HELP ME SET UP AN JOINT LEAKACCOUNT'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_recognizer(dataset[:5][\"audio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipelineã§ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’åˆ©ç”¨ã™ã‚‹\n",
    "\n",
    "pipeline()ã¯ï¼Œ[Hub](https://huggingface.co/models)ã‹ã‚‰ä»»æ„ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ï¼\n",
    "\n",
    "ä¾‹ãˆã°ï¼Œæ—¥æœ¬èªã®ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã¿ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"abhishek/autonlp-japanese-sentiment-59363\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9995540976524353}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"ã¿ãªã•ã‚“ã«ä¼šãˆã¦å¬‰ã—ã„ã§ã™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoClass\n",
    "\n",
    "`AutoClass`ã¯ï¼Œäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãã®åå‰ã‚„ãƒ‘ã‚¹ã‹ã‚‰è‡ªå‹•çš„ã«æ¨æ¸¬ã—ï¼Œé©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®ä¾¿åˆ©ãªã‚¯ãƒ©ã‚¹ã§ã™ï¼\n",
    "\n",
    "é©åˆ‡ãª`AutoClass`ã‚’é¸æŠã—ï¼Œãã‚Œã«é–¢ã™ã‚‹å‰å‡¦ç†ã‚¯ãƒ©ã‚¹ã‚’é¸æŠã™ã‚‹ã ã‘ã§æ¸ˆã¿ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoTokenizer\n",
    "\n",
    "ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã§ãã‚‹æ•°å€¤ã®é…åˆ—ã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ï¼\n",
    "ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå‡¦ç†ã¯ï¼Œå˜èªã‚’ã©ã®ã‚ˆã†ã«åˆ†å‰²ã™ã‚‹ã‹ãªã©ï¼Œå¤šãã®ãƒ«ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã™ï¼\n",
    "äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼Œãã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\n",
    "ãã®ãŸã‚ï¼ŒåŒã˜ãƒ¢ãƒ‡ãƒ«åã§ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"abhishek/autonlp-japanese-sentiment-59363\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸¡ã—ã¦ã¿ã¾ã—ã‚‡ã†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 12989, 11689, 893, 1136, 6426, 888, 1945, 11265, 12461, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(\"ã¿ãªã•ã‚“ã«ä¼šãˆã¦å¬‰ã—ã„ã§ã™\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã“ã§\n",
    "- `input_ids`: ãƒˆãƒ¼ã‚¯ãƒ³ ID ï¼ˆæ•´æ•°å€¤ï¼‰ã®ãƒªã‚¹ãƒˆ\n",
    "- `attention_mask`: ã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’å‘ã‘ã‚‹ã‹ã‚’ç¤ºã™ãƒã‚¹ã‚¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯å…¥åŠ›ã®ãƒªã‚¹ãƒˆã‚’ä¸ãˆã¦ï¼Œä¸€æ§˜ãªé•·ã•ã®ãƒãƒƒãƒã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n",
    "ã“ã®ã¨ãï¼Œå¿…è¦ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ãŸã‚Šï¼ŒãƒˆãƒªãƒŸãƒ³ã‚°ã—ãŸã‚Šã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_batch = tokenizer(\n",
    "    [\"ã¿ãªã•ã‚“ã«ä¼šãˆã¦å¬‰ã—ã„ã§ã™\", \"åˆ¥ã‚Œã‚‹ã®ãŒè¾›ã„ã§ã™\"],\n",
    "    padding=True,        # æœ€ã‚‚é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«åˆã‚ã›ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆ0è©°ã‚ï¼‰\n",
    "    truncation=True,     # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¶…ãˆã‚‹å ´åˆã¯åˆ‡ã‚Šæ¨ã¦\n",
    "    max_length=512,      # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°\n",
    "    return_tensors=\"pt\", # PyTorchã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’è¿”ã™\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2, 12989, 11689,   893,  1136,  6426,   888,  1945, 11265, 12461,\n",
      "             3],\n",
      "        [    2, 16170,  6365,   896,   862, 29301, 12461,     3,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(pt_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoModel\n",
    "\n",
    "`AutoModel`ã¯ï¼Œäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãã®åå‰ã‚„ãƒ‘ã‚¹ã‹ã‚‰è‡ªå‹•çš„ã«æ¨æ¸¬ã—ï¼Œé©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®ä¾¿åˆ©ãªã‚¯ãƒ©ã‚¹ã§ã™ï¼\n",
    "`AutoTokenizer`ã¨åŒæ§˜ã«ï¼Œé©åˆ‡ãª`AutoModel`ã‚’é¸æŠã—ï¼Œãã‚Œã«é–¢ã™ã‚‹å‰å‡¦ç†ã‚¯ãƒ©ã‚¹ã‚’é¸æŠã™ã‚‹ã ã‘ã§æ¸ˆã¿ã¾ã™ï¼ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"abhishek/autonlp-japanese-sentiment-59363\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‰å‡¦ç†æ¸ˆã¿ã®ãƒãƒƒãƒã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ã¦ã¿ã¾ã—ã‚‡ã†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **pt_batchã¯ï¼Œè¾æ›¸ã§ã‚ã‚‹pt_batchã‚’å±•é–‹ã—ã¦å¼•æ•°ã¨ã—ã¦æ¸¡ã—ã¾ã™ï¼\n",
    "pt_outputs = pt_model(**pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.8021,  3.9129],\n",
       "        [-2.0204,  2.5722]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pt_outputs`ã®`logits`ã¯ï¼Œsoftmaxé–¢æ•°ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ç¢ºç‡ã«å¤‰æ›ã§ãã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.4587e-04, 9.9955e-01],\n",
      "        [1.0024e-02, 9.8998e-01]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã‚‰ï¼ŒPreTrainedModel.save_pretrained()ã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã§ãã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256}\n"
     ]
    }
   ],
   "source": [
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ï¼ŒPreTrainedModel.from_pretrained()ã‚’ä½¿ã£ã¦èª­ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face Transformers ã®ãƒ¢ãƒ‡ãƒ«ã¯ï¼ŒPyTorchï¼ŒTensorFlowï¼ŒJAXã§ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ç›¸äº’ã«å¤‰æ›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n",
    "ï¼ˆå‰²æ„›ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚¯ãƒ©ã‚¹ã‚’ï¼Œäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã§ï¼Œã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fujie/.conda/envs/py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a500444d66a4434fb5256f717e46fe57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "# äº‹å‰å­¦ç¿’ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹è¨­å®šã‚’èª­ã¿è¾¼ã‚€\n",
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "my_config = AutoConfig.from_pretrained(model_name, n_heads=12)\n",
    "\n",
    "# èª­ã¿è¾¼ã‚“ã è¨­å®šã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–\n",
    "my_model = AutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer - PyTorchå‘ã‘ã®æœ€é©åŒ–ã•ã‚ŒãŸå­¦ç¿’ãƒ«ãƒ¼ãƒ—\n",
    "\n",
    "å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¯æ¨™æº–ã® `torch.nn.Module` ã§ã‚ã‚Šï¼Œé€šå¸¸ã®ãƒ«ãƒ¼ãƒ—ã§å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n",
    "\n",
    "Hugging Face Transformers ã§ã¯ï¼ŒPyTorchå‘ã‘ã«`Trainer`ã‚¯ãƒ©ã‚¹ã‚’æä¾›ã—ã¦ã„ã¦ï¼ŒåŸºæœ¬çš„ãªå­¦ç¿’ãƒ«ãƒ¼ãƒ—ã«åŠ ãˆã¦ï¼Œåˆ†æ•£å­¦ç¿’ï¼Œæ··åˆç²¾åº¦ãªã©ã®æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã™ï¼\n",
    "\n",
    "ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦ï¼Œé€šå¸¸ã¯`Trainer`ã«ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã—ã¾ã™:\n",
    "\n",
    "1. `PreTrainedModel`ã¾ãŸã¯`torch.nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f3924416af4be291f1ff216119e1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `TrainingArguments`ã«ã¯ï¼Œå¤‰æ›´ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼\n",
    "ä¾‹ãˆã°ï¼Œå­¦ç¿’ç‡ï¼Œãƒãƒƒãƒã‚µã‚¤ã‚ºï¼Œå­¦ç¿’ã™ã‚‹ã‚¨ãƒãƒƒã‚¯æ•°ãªã©ãŒå¤‰æ›´ã§ãã¾ã™ï¼æŒ‡å®šã—ãªã„å ´åˆã¯ï¼Œãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒä½¿ç”¨ã•ã‚Œã¾ã™:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./saved_model\", # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆ\n",
    "    learning_rate=2e-5,         # å­¦ç¿’ç‡\n",
    "    per_device_train_batch_size=8, # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    per_device_eval_batch_size=8,  # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    num_train_epochs=3,         # ã‚¨ãƒãƒƒã‚¯æ•°\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ï¼Œç”»åƒå‡¦ç†ï¼Œç‰¹å¾´æŠ½å‡ºå™¨ãªã©ã®å‰å‡¦ç†ã‚¯ãƒ©ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de126eddbac4c228a0391ba6202deb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408af410a84b4a9bbb1614a823772fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9ff9b584ba4bb9817147ad0e057b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a2421a2a5d49f0ada52ad26254cbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a8f0271766425faa0f9fc3cb26e980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617b976ae4a34e309883e3f8615d5978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef15613e2f04aa2baabba2849a33dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4b4bda51e0487da5b1980ab9d6c1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1284e7432b4bd8b69a8ae227f1764f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd47de16065b4a389b94e97b5b00c9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã™ã‚‹ãŸã‚ã®é–¢æ•°ã‚’ä½œæˆã—ã¾ã™:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map`ã‚’åˆ©ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«é©ç”¨ã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49552596949452497d35927fc1972b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b142226260748d2b90e729a4ac41bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8bcaa15fd043439a5d698ababc93d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã®ä¾‹ã®ãƒãƒƒãƒã‚’ä½œæˆã™ã‚‹ãŸã‚ã®`DataCollatorWithPadding`ã‚’ä½œæˆã—ã¾ã™:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ï¼Œã“ã‚Œã‚‰ã®ã‚¯ãƒ©ã‚¹ã‚’Trainerã«ã¾ã¨ã‚ã¾ã™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                 # ãƒ¢ãƒ‡ãƒ«\n",
    "    args=training_args,          # å­¦ç¿’è¨­å®š\n",
    "    train_dataset=dataset[\"train\"], # è¨“ç·´ãƒ‡ãƒ¼ã‚¿\n",
    "    eval_dataset=dataset[\"test\"],   # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿\n",
    "    tokenizer=tokenizer,          # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶\n",
    "    data_collator=data_collator,  # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ãƒ¼ã‚¿\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€å¾Œã«`train()`ã‚’å‘¼ã³å‡ºã—ã¦å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3201' max='3201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3201/3201 01:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.451700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.395200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.270300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.175200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.153200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3201, training_loss=0.2779122042454842, metrics={'train_runtime': 109.8821, 'train_samples_per_second': 232.886, 'train_steps_per_second': 29.131, 'total_flos': 293653315380000.0, 'train_loss': 0.2779122042454842, 'epoch': 3.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Trainer`ã‚’ã‚µãƒ–ã‚¯ãƒ©ã‚¹åŒ–ã™ã‚‹ã“ã¨ã§ï¼Œå­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n",
    "ã“ã‚Œã«ã‚ˆã‚Šï¼Œæå¤±é–¢æ•°ï¼Œã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ï¼Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãªã©ã®æ©Ÿèƒ½ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ï¼\n",
    "\n",
    "ä»–ã«ã‚‚ï¼Œ`Callbacks`ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ï¼\n",
    "ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’åˆ©ç”¨ã—ã¦ä»–ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨é€£æºã—ï¼Œå­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ç›£è¦–ã—ã¦é€²æ—çŠ¶æ³ã‚’å ±å‘Šã—ãŸã‚Šï¼Œå­¦ç¿’ã‚’æ—©æœŸã«åœæ­¢ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
