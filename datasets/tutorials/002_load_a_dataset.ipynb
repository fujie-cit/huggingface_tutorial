{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hubからのデータセットの読み込み（Load a dataset from the Hub）\n",
    "\n",
    "再現可能（reproductable）でアクセスしやすい（accessible）高品質なデータセットを見つけるのは難しいです．\n",
    "Hugging Face Datastesの一つの主要な目標は，任意のフォーマットまたはタイプのデータセットに簡単にアクセスする方法を提供することです．\n",
    "事のはじめとして最も簡単な方法は，Hugging Face Hubにある既存のデータセットを見つけて，Hugging Face Datasetsを使いダウンロードや生成をしてみることです．\n",
    "Hugging Face Hubは，コミュニティベースのNLP，画像処理，音声処理などのタスクのためのデータセットのコレクションです．\n",
    "\n",
    "このチュートリアルでは，rotten tomatoes と MinDS-14 データセットを使いますが，あなたの興味あるデータセットを一緒に読み込んでみるのもいいと思います．\n",
    "今すぐHubにアクセスして，あなたのタスクにあったデータセットを探してみましょう！\n",
    "\n",
    "## データセットの読み込み（Load a dataset）\n",
    "\n",
    "データセットをダウンロードする前に，データセットに関する一般的な情報を素早く得ることが助けになることがおおいです．\n",
    "データセットの情報は DatasetInfo に格納されていて，データセットの詳細や特性（features），データセットのサイズなどの情報を含めることができます．\n",
    "\n",
    "`load_dataset_builder()` を使って，データセットビルダ（dataset builder）を読み込み，ダウンロードせずにそのデータセットの属性を見ることができます:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder\n",
    "ds_builder = load_dataset_builder(\"rotten_tomatoes\")\n",
    "\n",
    "# inspect dataset description\n",
    "ds_builder.info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset features\n",
    "ds_builder.info.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットでよければ，`load_dataset()` を使ってデータセットを読み込むことができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits\n",
    "\n",
    "スプリット（Split）は，`train`や`test`のようなデータセットのサブセット（部分集合）です．\n",
    "データセットのスプリット名は`get_dataset_split_names()`関数で取得できます:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset_split_names\n",
    "\n",
    "get_dataset_split_names(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split`パラメータによって特定のスプリットを指定してデータセットを読み込むことができます．\n",
    "データセットスプリットを読み込むことで，`Dataset`オブジェクトが取得できます:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split`を指定しなかった場合，Hugging Face Datasets は代わりに`DatasetDict`オブジェクトを返します:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンフィギュレーション（Configurations）\n",
    "\n",
    "データセットの中にはいくつかのサブデータセットを含むものがあります．\n",
    "例えば，`MinDS-14`データセットはいくつかのサブデータセットがあり，それぞれは異なる言語のオーディオデータを含んでいます．\n",
    "これらのサブデータセットは`configurations`として知られいて，データセットを読み込むときに明確に一つ指定する必要があります．\n",
    "コンフィギュレーション名（configuration name）を指定しない場合，Hugging Face Datasets は`ValueError`を発生し，コンフィギュレーションを選択することを指示します．\n",
    "\n",
    "\n",
    "`get_dataset_config_names()`関数を使って，データセットで提供されている全ての可能なコンフィギュレーション名のリストを取得できます:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "configs = get_dataset_config_names(\"PolyAI/minds14\")\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好きなコンフィギュレーションを読み込むことができます:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "mindsFR = load_dataset(\"PolyAI/minds14\", \"fr-FR\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リモートコード\n",
    "\n",
    "特定のデータセットのリポジトリは，データセットを生成するためのPythonコードである読み込み用のスクリプトを含みます．\n",
    "それらのデータセットは全般的に Parquet by Hugging Face にエクスポートされ，Hugging Face Datasets では読み込み用スクリプトを実行することなくデータセットを高速に読み込むことができます．\n",
    "\n",
    "もし Parguet によるエクスポートが不可能でも，`load_dataset`によってPythonコードを持つリポジトリのデータセットを利用することは可能です．\n",
    "Hubにアップロードされたファイルやコードは全てマルウェアのスキャンが行われますが，データセット読み込み用のスクリプトやそのプログラマを確認し，あなたの計算機上で悪意あるコードを実行しないようにするべきです．\n",
    "`trust_remote_code=True`を有効にして読み込み用スクリプトを持つデータセットを利用するべきです．そうしないと，警告を受けることになるでしょう:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注: C4コーパスは非常に大きいため、データセットのダウンロードには時間がかかる場合があります.\n",
    "# この例では、データセットのダウンロードをスキップしています.\n",
    "\n",
    "from datasets import get_dataset_config_names, get_dataset_split_names, load_dataset\n",
    "\n",
    "# c4 = load_dataset(\"c4\", \"en\", trust_remote_code=True)\n",
    "# print(get_dataset_config_names(\"c4\"))\n",
    "# print(get_dataset_split_names(\"c4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 次期メジャーリリースでは，`trust_remote_code`はデフォルトで`False`になります．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
